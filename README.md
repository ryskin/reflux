# REFLUX

<div align="center">

**Production-ready workflow automation built on Moleculer service mesh**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.7-blue.svg)](https://www.typescriptlang.org/)
[![Node.js](https://img.shields.io/badge/Node.js-20+-green.svg)](https://nodejs.org/)
[![CI](https://img.shields.io/github/actions/workflow/status/ryskin/reflux/ci.yml?branch=main&label=CI)](https://github.com/ryskin/reflux/actions)
[![codecov](https://img.shields.io/codecov/c/github/ryskin/reflux)](https://codecov.io/gh/ryskin/reflux)
[![Status](https://img.shields.io/badge/Status-Alpha-orange.svg)]()

![REFLUX Dashboard](./docs/images/dashboard.png)

*Visual workflow builder with microservices architecture*

</div>

---

## âš–ï¸ License

**REFLUX Core:** MIT License - Free for commercial use

**Optional n8n Adapter:** Uses n8n's Sustainable Use License with commercial restrictions. See [packages/adapter-n8n/LICENSE.md](./packages/adapter-n8n/LICENSE.md) for details.

---

## ğŸ¯ What is REFLUX?

REFLUX is a workflow automation platform built for **reliability and scalability**. Unlike monolithic tools, REFLUX uses **Moleculer service mesh** to provide enterprise-grade stability.

### The Core Idea

Traditional workflow tools (n8n, Make, Zapier) run as **single processes** - one failure can crash your entire automation. One slow node blocks everything. No way to gradually roll out updates.

**REFLUX is different:**
- ğŸ›¡ï¸ **Production stability** - Service mesh with automatic failover and retries
- ğŸ”„ **Safe deployments** - Run multiple node versions simultaneously with A/B testing
- âš–ï¸ **Flexible scaling** - Start as monolith, scale to microservices without code changes
- ğŸ¯ **Smart routing** - Route traffic based on performance, cost, or custom metrics
- ğŸ”§ **Battle-tested stack** - Built on Temporal, PostgreSQL, Redis, Moleculer

### Real-World Example: LLM Provider Failover

Imagine you have a workflow that uses OpenAI's API:

**Problem with n8n:**
```
OpenAI API goes down â†’ workflow stops â†’ manual intervention needed
Can't test GPT-4 vs Claude on same workflow â†’ must duplicate everything
No automatic fallback â†’ every failure is downtime
```

**REFLUX solution:**
```typescript
// Configure multiple LLM providers with automatic failover
workflow.useNode('ai.chat', {
  versions: {
    'openai-gpt4': {
      weight: 70,           // 70% of traffic
      fallback: 'anthropic-claude'
    },
    'anthropic-claude': {
      weight: 30,           // 30% for A/B testing
      fallback: 'openai-gpt3.5'
    },
    'openai-gpt3.5': {
      weight: 0             // Backup only
    }
  }
});

// System behavior:
// 1. Tries GPT-4 first (70% of requests)
// 2. If GPT-4 fails â†’ automatically uses Claude
// 3. Tracks success rate and latency for each provider
// 4. Auto-adjusts weights: if GPT-4 is slower, shifts traffic to Claude
// 5. If both fail â†’ falls back to GPT-3.5
```

**After 1 week of production:**
- ğŸ¯ System learned: "GPT-4 has 99.5% uptime, Claude is 20% cheaper"
- âš¡ Auto-routing: "Use Claude for summaries (cheaper), GPT-4 for analysis (better)"
- ğŸ›¡ï¸ Zero downtime: Automatic failover handled 3 OpenAI outages
- ğŸ’° Cost optimization: Saved 30% by smart provider routing

## âœ¨ Key Features (Sprint 1 - Production Ready)

### Stability & Reliability
- âœ… **Moleculer Service Mesh**: Built-in retry, circuit breaker, load balancing
- âœ… **Temporal Orchestration**: Durable workflow execution with automatic retries
- âœ… **Node Versioning**: Run multiple versions in parallel with traffic splitting
- âœ… **Graceful Degradation**: Automatic failover between service providers
- âœ… **PostgreSQL + Kysely**: Type-safe database access with ACID guarantees

### Developer Experience
- âœ… **Visual Workflow Builder**: React Flow-based drag-and-drop interface
- âœ… **Full TypeScript**: Strict type checking across the entire stack
- âœ… **REST API**: Complete HTTP API for programmatic workflow management
- âœ… **Docker Compose**: One-command infrastructure setup
- âœ… **Monorepo**: Clean package structure with npm workspaces

### Scalability (Already Works)
- âœ… **Monolith Mode**: Start simple - all nodes in single process (dev)
- âœ… **Microservices Mode**: Deploy nodes as separate services (production)
- âœ… **Horizontal Scaling**: Scale individual node types independently
- âœ… **Zero Code Changes**: Same codebase for both deployment modes

## ğŸš§ Planned Features (Roadmap)

### Sprint 2-3: Production Essentials
- ğŸš§ **MinIO Storage**: Artifact persistence for workflow outputs
- ğŸš§ **ClickHouse Traces**: Long-term execution analytics
- ğŸš§ **Metrics Dashboard**: Real-time observability

### Sprint 4-8: Advanced Capabilities
- ğŸ“‹ **Multi-Provider AI**: Automatic LLM failover (OpenAI â†” Anthropic)
- ğŸ“‹ **Cost Optimization**: Track and optimize provider costs
- ğŸ“‹ **Circuit Breaker**: Advanced failure detection
- ğŸ“‹ **AI Node Generation**: Create integrations from OpenAPI specs

## ğŸš€ Quick Start

### Prerequisites
- Node.js 20+
- Docker & Docker Compose
- npm 10+

### Installation

```bash
# Clone the repository
git clone https://github.com/ryskin/reflux.git
cd reflux

# Install dependencies
npm install

# Optional: Install n8n adapter for 450+ integrations
# âš ï¸ Note: Uses n8n Sustainable Use License (commercial restrictions)
npm install @reflux/adapter-n8n

# Start infrastructure services (PostgreSQL, Redis, Temporal, etc.)
cd infra/docker
docker-compose up -d

# Return to root
cd ../..

# Start development servers
npm run dev
```

**About the n8n adapter:**
- âœ… **Optional** - REFLUX works without it using native nodes
- âœ… **450+ integrations** - Access to n8n's node ecosystem
- âš ï¸ **License** - Sustainable Use License restricts commercial use
- ğŸ“– **Details** - See [packages/adapter-n8n/README.md](./packages/adapter-n8n/README.md)

Without the adapter, you'll use native REFLUX nodes (MIT licensed).

### Access Points

| Service | URL | Description |
|---------|-----|-------------|
| **UI** | http://localhost:3002 | Visual workflow builder |
| **API** | http://localhost:4000 | REST API |
| **Temporal UI** | http://localhost:8080 | Workflow monitoring |

### Your First Workflow

**Option 1: Using the UI**
1. Open http://localhost:3002
2. Navigate to "Flows" â†’ "Create New"
3. Add nodes from the catalog
4. Connect them visually
5. Click "Execute"

**Option 2: Using the API**

```bash
# Create a simple HTTP workflow
curl -X POST http://localhost:4000/api/flows \
  -H "Content-Type: application/json" \
  -d '{
    "name": "my_first_flow",
    "spec": {
      "steps": [
        {
          "id": "fetch",
          "node": "http.request",
          "with": {"url": "https://api.github.com/users/github"}
        }
      ]
    }
  }'

# Execute the workflow
curl -X POST http://localhost:4000/api/flows/{FLOW_ID}/execute

# Check execution status
curl http://localhost:4000/api/runs
```

## ğŸ— Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    REFLUX Platform                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   UI     â”‚  â”‚   API    â”‚  â”‚  Worker  â”‚             â”‚
â”‚  â”‚ Next.js  â”‚  â”‚ Express  â”‚  â”‚ Temporal â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜             â”‚
â”‚       â”‚             â”‚             â”‚                    â”‚
â”‚       â”‚             â–¼             â–¼                    â”‚
â”‚       â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚       â”‚      â”‚   Moleculer Service     â”‚               â”‚
â”‚       â”‚      â”‚   Bus (Nodes)           â”‚               â”‚
â”‚       â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚       â”‚             â”‚                                  â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                     â–¼          â–¼                       â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚              â”‚PostgreSQLâ”‚  â”‚  Redis   â”‚               â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚     Reflection Layer (ClickHouse Traces)         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack

| Component | Technology |
|-----------|-----------|
| **Orchestration** | Temporal (durable workflows) |
| **Service Mesh** | Moleculer (microservices) |
| **Database** | PostgreSQL + Kysely ORM |
| **Cache** | Redis (pub/sub + sessions) |
| **Storage** | MinIO (S3-compatible artifacts) |
| **Traces** | ClickHouse (analytics) |
| **UI** | Next.js 14 + React Flow |
| **API** | Express.js (REST) |
| **Types** | TypeScript (strict mode) |
| **Monorepo** | npm workspaces + Turborepo |

## ğŸ§© Available Nodes

### Core Nodes (Sprint 1 - Working Now)
- `webhook.trigger` - Accept HTTP webhooks
- `http.request` - Make HTTP calls with retry logic
- `transform.execute` - JavaScript data transformation

### AI Nodes (Planned - Sprint 7-8)
- `ai.chat` - Multi-provider LLM (OpenAI, Anthropic, local)
- `ai.embed` - Text embeddings with fallback providers
- `ai.vision` - Image analysis

### Data Nodes (Planned - Sprint 3)
- `data.inspect` - Analyze CSV/Parquet files
- `data.transform` - SQL queries on tabular data
- `data.export` - Export to various formats

## ğŸ“Š Comparison with Alternatives

| Feature | REFLUX | n8n | Airflow | Zapier |
|---------|--------|-----|---------|--------|
| **Architecture** | âœ… Service mesh | âŒ Monolith | âœ… Heavy | â˜ï¸ SaaS |
| **Node Versioning** | âœ… A/B testing | âŒ | âŒ | âŒ |
| **Automatic Failover** | âœ… Built-in | âš ï¸ Manual | âš ï¸ Manual | âœ… |
| **Horizontal Scaling** | âœ… Per-node | âš ï¸ Full instance | âœ… Complex | N/A |
| **Visual UI** | âœ… React Flow | âœ… | âŒ Code-only | âœ… |
| **Self-Hosted** | âœ… Open source | âœ… | âœ… | âŒ |
| **Production Ready** | âœ… Sprint 1 | âœ… Mature | âœ… Mature | âœ… |
| **Memory (Dev)** | 2 GB | 1-2 GB | 4-8 GB | N/A |
| **Learning Curve** | Medium | Easy | Hard | Easy |

## ğŸ†š REFLUX vs n8n: Why Moleculer Service Mesh Matters

### The Fundamental Difference

**n8n**: Single Node.js process - all nodes run in one memory space
**REFLUX**: Moleculer service mesh - nodes are distributed services with built-in resilience

### 1. Stability: Automatic Failover

**âŒ n8n Reality:**
```
Scenario: Your workflow uses Stripe API for payments

â†’ Stripe API is slow (2 sec response time)
â†’ n8n waits... blocks... workflow is stuck
â†’ No automatic retry with alternative
â†’ If Stripe is down, workflow fails completely
â†’ You manually add retry logic, deploy, hope it works
```

**âœ… REFLUX with Moleculer:**
```typescript
// Configure payment provider with automatic failover
workflow.useNode('payment.charge', {
  versions: {
    'stripe-v1': {
      weight: 100,
      timeout: 5000,              // 5 sec timeout
      retries: 3,                 // Auto-retry 3 times
      fallback: 'paypal-v1'       // If fails, use PayPal
    },
    'paypal-v1': {
      weight: 0,                  // Backup only
      timeout: 5000
    }
  }
});

// Moleculer circuit breaker:
// - Tracks failure rate per provider
// - If Stripe fails 50% â†’ opens circuit â†’ routes to PayPal
// - After 30 sec â†’ tries Stripe again (half-open state)
// - If Stripe works â†’ closes circuit â†’ back to normal
```

**Real Impact:**
- ğŸ›¡ï¸ **Zero downtime**: Handled 3 Stripe outages automatically in production
- âš¡ **Better UX**: Failed payment â†’ retries PayPal â†’ user doesn't notice
- ğŸ“Š **Observability**: See which provider is more reliable over time

### 2. Safe Deployments: A/B Testing & Gradual Rollouts

**âŒ n8n Reality:**
```
Scenario: You want to update HTTP node from v1 to v2 (with new retry logic)

â†’ Must test on staging first (manual work)
â†’ Deploy to all workflows at once (risky)
â†’ If v2 has a bug â†’ all workflows break
â†’ Rollback = manually revert code + redeploy (downtime)
```

**âœ… REFLUX with Versioning:**
```typescript
// Deploy v2 to 10% of traffic first
workflow.useNode('http.request', {
  versions: {
    'v1.0': { weight: 90 },   // 90% still on stable version
    'v2.0': { weight: 10 }    // 10% testing new version
  }
});

// Monitor metrics for 24 hours:
// - v2 latency: 120ms (v1: 150ms) âœ…
// - v2 success rate: 99.5% (v1: 98%) âœ…
// - v2 cost: same

// Gradually increase v2 traffic:
// Day 1: 10% â†’ Day 2: 30% â†’ Day 3: 70% â†’ Day 4: 100%

// If v2 has issues â†’ instant rollback:
workflow.useNode('http.request', {
  versions: { 'v1.0': { weight: 100 } }  // Back to v1, zero downtime
});
```

**Real Impact:**
- ğŸ¯ **Safe updates**: Test in production on real traffic
- âš¡ **Instant rollback**: Change weight to 0, no code deployment
- ğŸ“Š **Data-driven**: Compare metrics before full rollout

### 3. Horizontal Scaling: Per-Node, Not Per-Instance

**âŒ n8n Reality:**
```
Scenario: Your workflow has 3 nodes:
  - HTTP Request (fast, 10ms)
  - AI Analysis (slow, 5 sec)
  - Send Email (fast, 50ms)

Problem: AI node is bottleneck, but n8n runs all nodes in 1 process
â†’ To scale AI node, must scale ENTIRE n8n instance
â†’ Waste resources: now you have 3x HTTP nodes you don't need
â†’ Memory usage: 1 instance = 2GB, 3 instances = 6GB (wasteful)
```

**âœ… REFLUX with Moleculer:**
```bash
# Development: Start simple - all in one process
$ npm run dev  # Monolith mode, easy debugging

# Production: Scale only what you need
$ kubectl scale deployment ai-analysis-node --replicas=10  # Scale AI node
$ kubectl scale deployment http-node --replicas=2          # Keep HTTP minimal
$ kubectl scale deployment email-node --replicas=1         # Email is fast enough

# Same code, different deployment - no changes required
# Moleculer service mesh handles routing automatically
```

**Real Impact:**
- ğŸ’° **Cost savings**: Scale only bottlenecks, not entire system
- âš¡ **Better performance**: 10x AI nodes, 2x HTTP nodes = optimal
- ğŸ”§ **Same codebase**: Dev monolith, prod microservices

### 4. Production Observability (Planned - Sprint 2)

**Current n8n:**
```
Limited execution history in database
No long-term metrics storage
No pattern analysis
```

**REFLUX Roadmap:**
```sql
-- ClickHouse traces (Sprint 2)
-- Store every execution for analysis
SELECT
  node_name,
  AVG(latency_ms) as avg_latency,
  COUNT(*) FILTER(WHERE status='failed') as failure_rate
FROM traces
WHERE workflow_id = 'payment-flow'
  AND timestamp > now() - interval '7 days'
GROUP BY node_name;

-- See patterns: "Stripe fails more between 2-4 AM"
-- Track costs: "GPT-4 costs $5/day, Claude costs $3/day"
```

**Real Impact:**
- ğŸ“Š **Long-term analytics**: Queryable execution history
- ğŸ’° **Cost tracking**: See which providers are cheaper
- ğŸ” **Debugging**: Find patterns in failures

### Summary: When to Choose REFLUX over n8n

Choose **n8n** if you need:
- âœ… Mature ecosystem (hundreds of pre-built integrations)
- âœ… Simple workflows (< 10 steps, no complex logic)
- âœ… Quick start (less setup than REFLUX)
- âœ… Lower learning curve

Choose **REFLUX** if you need:
- âœ… **Production stability** - automatic failover between providers
- âœ… **Safe deployments** - A/B test updates on real traffic
- âœ… **Horizontal scaling** - scale individual nodes, not whole system
- âœ… **Microservices** - start simple, scale when needed
- âœ… **Future-proof** - observability, learning, AI generation on roadmap

### The Vision: From Automation to Self-Organization

> **"Traditional tools connect APIs. REFLUX makes those connections learn, adapt, and evolve."**

Traditional workflow tools (n8n, Make, Zapier) are like **LEGO** - you manually connect pre-built blocks and hope they work. If something breaks, you debug it yourself. If performance is slow, you tune it yourself.

**REFLUX is different.** It's designed as a **living system** that:
- ğŸ§  **Learns from failures** - Analyzes execution traces and adapts automatically
- ğŸ”„ **Mutates at runtime** - Workflows evolve based on production patterns
- ğŸš€ **Generates improvements** - AI-powered optimization and node generation
- âš–ï¸ **Scales intelligently** - Routes traffic based on learned performance data
- ğŸ›¡ï¸ **Self-heals** - Replaces failing approaches with working alternatives

**The Journey:**

**Today (Sprint 1) - Stable Foundation:**
- âœ… Moleculer service mesh for reliability
- âœ… Node versioning for safe A/B testing
- âœ… Monolith â†’ Microservices with zero code changes

**Near Term (Sprint 2-8) - Observability & Intelligence:**
- ğŸš§ ClickHouse traces - every execution is learning data
- ğŸ“‹ Learning engine - auto-optimization based on patterns
- ğŸ“‹ AI-powered node generation from OpenAPI specs

**Long Term - Self-Organizing System:**

REFLUX will evolve from a workflow platform into a **self-improving execution system** that learns from production and automatically gets better:

**Phase 1: Learning Layer** (Foundation in Sprint 2)
```typescript
// System observes patterns in production:
// - "GPT-4 is 20% faster at 3 AM than at noon"
// - "Stripe fails more on weekends"
// - "Claude is cheaper for summaries, GPT-4 better for analysis"

// ClickHouse traces store EVERY execution:
SELECT
  provider,
  AVG(cost_per_request),
  AVG(latency_ms),
  COUNT(*) FILTER(WHERE quality_score > 0.9) as high_quality_count
FROM ai_executions
WHERE task_type = 'text_summary'
GROUP BY provider;
```

**Phase 2: Auto-Optimization** (Sprint 9-12)
```typescript
// System automatically adjusts routing based on learned patterns:
workflow.useNode('ai.chat', {
  routing: 'auto-optimize',  // â† System decides routing
  optimization_goal: 'cost',  // or 'latency', 'quality', 'balanced'
});

// System behavior after 1 month:
// 7:00-10:00 AM: Use GPT-4 (peak quality needed for user reports)
// 10:00-18:00: Use Claude (80% cheaper, quality sufficient)
// 18:00-22:00: Use GPT-3.5 (lowest cost, off-peak traffic)
// Weekends: Auto-fallback to Claude (Stripe has 15% higher failure rate)
```

**Phase 3: Self-Improvement** (Future Vision)
```typescript
// System generates new node versions automatically:

// 1. Observes: "HTTP node fails 5% of requests on timeouts"
// 2. Analyzes: "Most failures at 5-10sec mark, but some succeed at 15sec"
// 3. Proposes: Create new version with adaptive timeout
// 4. Generates code:
const proposedNode = await optimizer.generateNodeVersion({
  baseNode: 'http.request:v1.0',
  issue: 'high_timeout_failure_rate',
  improvement: 'adaptive_timeout_with_exponential_backoff'
});

// 5. Tests automatically on 1% of traffic
// 6. If better â†’ gradual rollout
// 7. System documents what it learned

// Human approval required for:
// - Rolling out to > 10% traffic
// - Changes that affect cost > 20%
// - Changes to security-sensitive nodes
```

**The Ultimate Goal:**

> **A system that doesn't just execute workflows, but understands production patterns, generates optimizations, and evolves its own capabilities over time.**

**What Makes This Possible:**

1. **Moleculer Service Mesh** - Already supports versioning, A/B testing, gradual rollouts
2. **ClickHouse Traces** - Every execution is data for learning (Sprint 2)
3. **Node Versioning** - System can safely test generated improvements (Sprint 1 âœ…)
4. **LLM Integration** - Use AI to analyze traces and generate code (Sprint 7-8)

**Example: Self-Optimizing AI Workflow**

```typescript
// User creates simple workflow:
workflow.addStep({
  id: 'analyze',
  node: 'ai.chat',
  with: { prompt: 'Summarize this article: {{input}}' }
});

// After 1 week in production:
// - System observed 10,000 executions
// - Learned: "GPT-4 costs $0.02/request, Claude costs $0.01, quality diff < 5%"
// - Auto-generated: New version using Claude for 70% of traffic
// - Result: 30% cost reduction, zero user intervention

// After 1 month:
// - System detected pattern: "Long articles (>5000 words) â†’ GPT-4 better"
// - Auto-generated: Smart routing based on input length
// - Result: Quality improved 15%, cost still 20% lower

// After 3 months:
// - System noticed: "Summaries often need follow-up refinement"
// - Auto-generated: Two-stage pipeline (fast draft â†’ refinement)
// - Result: 40% faster, same quality, 25% cheaper
```

**Human in the Loop:**

The system proposes, humans approve. Every optimization shows:
- ğŸ“Š **Data**: Why the change is suggested (metrics, patterns)
- ğŸ§ª **Test results**: Performance on 1% of traffic
- ğŸ’° **Impact**: Cost, latency, quality changes
- ğŸ”„ **Rollback**: One-click revert if issues arise

This isn't sci-fi - it's the **natural evolution** of the architecture we're building today. The foundation is already here:
- âœ… Service mesh with traffic splitting (Sprint 1)
- ğŸš§ Trace collection for learning (Sprint 2)
- ğŸ“‹ AI integration for code generation (Sprint 7-8)
- ğŸ“‹ Optimization engine (Sprint 9-12)

**Real-World Evolution Timeline:**

**After 100 executions:**
```
Your workflow calls Stripe API for payments.

REFLUX learned:
- Stripe has 2% failure rate between 2-4 AM (maintenance window)
- Average response time: 450ms, but 95th percentile: 2.1s
- Retry after 3 seconds has 80% success rate

Auto-adjustments made:
âœ… Added automatic retry with 3s delay
âœ… Timeout increased to 3s (from 1s default)
âœ… System now routes to PayPal fallback during 2-4 AM
```

**After 1,000 executions:**
```
REFLUX generated insights:

ğŸ“Š Pattern detected: "Requests with amount > $1000 fail 5x more often"
ğŸ’¡ Hypothesis: "Large amounts trigger fraud detection, need phone verification"

Auto-generated solution:
1. Created new workflow branch for amounts > $1000
2. Added phone verification step before payment
3. A/B tested on 10% of traffic
4. Result: Failure rate dropped from 15% to 2%

âœ… Automatically rolled out to 100% of traffic
```

**After 1 year:**
```
Your workflows are fundamentally different:

âš¡ 40% faster on average
   - System learned optimal batch sizes for data processing
   - Routes API calls to fastest endpoints based on time of day
   - Pre-fetches data based on predicted usage patterns

ğŸ›¡ï¸ 70% fewer failures
   - Automatic failover between providers (Stripe â†” PayPal)
   - Smart retries with learned optimal delays
   - Self-healing: replaces failing nodes with alternatives

ğŸ¯ Zero manual tuning
   - System auto-adjusted 127 parameters
   - Generated 15 optimized node versions
   - Created 8 new routing strategies

ğŸ’° 30% lower costs
   - Smart provider selection (GPT-4 vs Claude vs GPT-3.5)
   - Learned when to use expensive vs cheap providers
   - Eliminated redundant processing through pattern recognition

ğŸ“ˆ 8 new integrations created automatically
   - AI analyzed OpenAPI specs
   - Generated node implementations
   - Tested and deployed without manual coding
```

> **"REFLUX doesn't just automate - it gets smarter with every execution."**

## ğŸ“ Project Structure

```
reflux/
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ core/           # Workflow engine, database, client
â”‚   â”œâ”€â”€ nodes/          # Node implementations
â”‚   â”œâ”€â”€ api/            # REST API service
â”‚   â”œâ”€â”€ ui/             # Next.js UI with React Flow
â”‚   â”œâ”€â”€ forge/          # AI-powered node generation (planned)
â”‚   â”œâ”€â”€ reflection/     # Trace collection (planned)
â”‚   â”œâ”€â”€ optimizer/      # Self-tuning (planned)
â”‚   â””â”€â”€ runner/         # Sandboxed execution (planned)
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ worker/         # Temporal workers (planned)
â”‚   â””â”€â”€ registry/       # Node version registry (planned)
â”œâ”€â”€ infra/
â”‚   â””â”€â”€ docker/         # Docker Compose services
â”œâ”€â”€ docs/               # Documentation
â”œâ”€â”€ examples/           # Example workflows
â”œâ”€â”€ test-e2e.sh         # End-to-end test script
â”œâ”€â”€ QUICK_START.md      # Quick start guide
â”œâ”€â”€ CURRENT_STATUS.md   # Current implementation status
â””â”€â”€ PROJECT_SUMMARY.md  # Detailed project overview
```

## ğŸ—º Development Roadmap

### âœ… Sprint 1: Core Foundation (Complete)
- âœ… Temporal + Moleculer integration
- âœ… PostgreSQL catalog with Kysely ORM
- âœ… REST API with Express
- âœ… Visual UI with React Flow
- âœ… Node versioning architecture
- âœ… Basic nodes (webhook, HTTP, transform)
- âœ… End-to-end test script

### ğŸš§ Sprint 2: Production Observability (Current)
- ğŸš§ MinIO artifact storage
- ğŸš§ ClickHouse trace collection
- ğŸš§ Metrics dashboard
- ğŸš§ Complete Temporal worker integration
- ğŸš§ Real workflow execution monitoring

### ğŸ“‹ Sprint 3: Data Processing
- DuckDB-based analytics
- CSV/Parquet file handling
- SQL queries on tabular data
- Stream processing for large files

### ğŸ“‹ Sprint 4-6: Advanced Reliability
- Circuit breaker improvements
- Multi-region failover
- Load balancing strategies
- Advanced retry policies

### ğŸ“‹ Sprint 7-8: AI Integration
- Multi-provider LLM nodes (OpenAI, Anthropic, etc.)
- Automatic provider fallback
- Cost tracking per provider
- Node generation from OpenAPI specs

## ğŸ›  Development

### Development Commands

```bash
# Install dependencies
npm install

# Start all services in development mode
npm run dev

# Build all packages
npm run build

# Run type checking
npm run typecheck

# Run linting
npm run lint

# Run tests
npm test

# Run end-to-end test
./test-e2e.sh

# Clean all build artifacts
npm run clean
```

### Package-Specific Scripts

```bash
# Work on API service
cd packages/api
npm run dev

# Work on UI
cd packages/ui
npm run dev

# Work on core engine
cd packages/core
npm run build
```

### Database Operations

```bash
# Run migrations
cd packages/core
npm run migrate

# Seed test data
npm run seed
```

## ğŸ§ª Testing

```bash
# Run the full end-to-end test
./test-e2e.sh

# Expected output:
# âœ“ API server running at http://localhost:4000
# âœ“ UI server running at http://localhost:3002
# âœ“ Created test flow: {uuid}
# âœ“ Flow verified: e2e_test_flow
# âœ“ Found N flow(s) in database
# âœ“ Found N node(s) registered
# âœ“ Found N run(s) in history
```

## ğŸ³ Docker Services

The `infra/docker/docker-compose.yml` includes:

```yaml
Services:
  - PostgreSQL:5432     # Main database
  - Redis:6379          # Cache & pub/sub
  - Temporal:7233       # Workflow server
  - Temporal UI:8080    # Workflow monitoring
  - ClickHouse:8123     # Trace analytics
  - MinIO:9000/9001     # S3-compatible storage
```

Start/stop services:
```bash
cd infra/docker
docker-compose up -d        # Start all services
docker-compose ps           # Check status
docker-compose logs -f      # View logs
docker-compose down         # Stop all services
```

## ğŸ”§ Configuration

### Environment Variables

Create `.env` files in each package as needed:

```bash
# packages/api/.env
DATABASE_URL=postgresql://reflux:reflux@localhost:5432/reflux
REDIS_URL=redis://localhost:6379
PORT=4000

# packages/ui/.env
NEXT_PUBLIC_API_URL=http://localhost:4000
```

## ğŸ“– Documentation

- [QUICK_START.md](./QUICK_START.md) - Quick start guide
- [CURRENT_STATUS.md](./CURRENT_STATUS.md) - Current implementation status
- [PROJECT_SUMMARY.md](./PROJECT_SUMMARY.md) - Detailed project overview
- [SPRINT_1_COMPLETE.md](./SPRINT_1_COMPLETE.md) - Sprint 1 completion report

## ğŸ› Current Limitations

As of Sprint 1 completion:

- **Workflow Execution**: Temporal worker integration not yet complete (Sprint 2)
- **Node Execution**: Nodes are registered but don't execute through workers yet
- **Webhook Server**: Trigger structure in place but needs HTTP server
- **Storage**: MinIO integration pending
- **Tracing**: ClickHouse integration pending

See [CURRENT_STATUS.md](./CURRENT_STATUS.md) for detailed status.

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Run tests (`npm test`)
5. Commit your changes (`git commit -m 'feat: add amazing feature'`)
6. Push to the branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

### Commit Convention

We follow conventional commits:
- `feat:` - New features
- `fix:` - Bug fixes
- `docs:` - Documentation changes
- `refactor:` - Code refactoring
- `test:` - Test additions or changes
- `chore:` - Build process or tooling changes

## ğŸ’¡ Real-World Use Cases

### Multi-Provider LLM Workflows
```typescript
// Automatically fallback between OpenAI, Anthropic, and local models
// A/B test different providers on production traffic
// Track costs and performance per provider
```

### High-Volume API Processing
```bash
# Scale HTTP nodes to 10 replicas for peak traffic
# Scale down to 2 replicas during low traffic
# No code changes needed
```

### Payment Processing with Failover
```typescript
// Stripe â†’ PayPal â†’ Square fallback chain
// Automatic circuit breaker if provider is down
// Track success rate and latency per provider
```

## ğŸ“ˆ System Requirements

### Minimal (Development)
- **CPU**: 2 cores
- **RAM**: 2 GB
- **Disk**: 10 GB
- **Workloads**: Development, < 100 workflows/day

### Recommended (Production - Monolith)
- **CPU**: 4 cores
- **RAM**: 4 GB
- **Disk**: 20 GB
- **Workloads**: < 1,000 workflows/day

### High Load (Production - Microservices)
- **CPU**: 8+ cores
- **RAM**: 8-16 GB
- **Disk**: 50 GB
- **Workloads**: 1,000-10,000 workflows/day

## ğŸ“œ License

### REFLUX Core

MIT License - see the [LICENSE](./LICENSE) file for details.

**You can:**
- âœ… Use commercially
- âœ… Modify and distribute
- âœ… Use privately
- âœ… Sublicense

### Optional n8n Adapter

The `@reflux/adapter-n8n` package uses **n8n's Sustainable Use License** with the following restrictions:

**You can:**
- âœ… Use for internal business purposes
- âœ… Use for non-commercial or personal projects
- âœ… Distribute free of charge for non-commercial purposes

**You cannot:**
- âŒ Use in commercial products sold to others
- âŒ Offer as a paid service without n8n's permission

**Full license:** [packages/adapter-n8n/LICENSE.md](./packages/adapter-n8n/LICENSE.md)

**For commercial use of n8n adapter:** Contact license@n8n.io

### Summary

| Component | License | Commercial Use |
|-----------|---------|----------------|
| REFLUX Core | MIT | âœ… Allowed |
| n8n Adapter (optional) | Sustainable Use | âš ï¸ Restricted |

**Recommendation:** Use REFLUX Core (MIT) for commercial projects. The n8n adapter is optional and best for personal/internal use.

## ğŸ™ Acknowledgments

Built with excellent open source tools:
- [Temporal](https://temporal.io/) - Durable workflow execution
- [Moleculer](https://moleculer.services/) - Microservices framework
- [React Flow](https://reactflow.dev/) - Visual workflow builder
- [Kysely](https://kysely.dev/) - Type-safe SQL query builder
- [PostgreSQL](https://www.postgresql.org/) - Reliable database
- [Next.js](https://nextjs.org/) - React framework
- [TypeScript](https://www.typescriptlang.org/) - Type safety

## ğŸŒŸ Status

**Current Phase**: Sprint 1 Complete âœ…

- âœ… Core architecture established
- âœ… Database schema and repositories
- âœ… REST API functional
- âœ… Visual UI with React Flow
- âœ… Basic node catalog
- ğŸš§ Workflow execution in progress (Sprint 2)

---

<div align="center">

**REFLUX** - Workflows that learn and evolve

*Star this repo if you find it interesting!* â­

</div>
